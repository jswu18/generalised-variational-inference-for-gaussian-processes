@article{wild2022generalized,
  title={Generalized variational inference in function spaces: Gaussian measures meet Bayesian deep learning},
  author={Wild, Veit David and Hu, Robert and Sejdinovic, Dino},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={3716--3730},
  year={2022}
}
@article{knoblauch2022optimization,
  title={An optimization-centric view on Bayesâ€™ rule: Reviewing and generalizing variational inference},
  author={Knoblauch, Jeremias and Jewson, Jack and Damoulas, Theodoros},
  journal={Journal of Machine Learning Research},
  volume={23},
  number={132},
  pages={1--109},
  year={2022}
}
@phdthesis{matthews2017scalable,
  title={Scalable Gaussian process inference using variational methods},
  author={Matthews, Alexander Graeme de Garis},
  year={2017},
  school={University of Cambridge}
}

@article{novak2019neural,
  title={Neural tangents: Fast and easy infinite neural networks in python},
  author={Novak, Roman and Xiao, Lechao and Hron, Jiri and Lee, Jaehoon and Alemi, Alexander A and Sohl-Dickstein, Jascha and Schoenholz, Samuel S},
  journal={arXiv preprint arXiv:1912.02803},
  year={2019}
}
@article{abdar2021review,
  title={A review of uncertainty quantification in deep learning: Techniques, applications and challenges},
  author={Abdar, Moloud and Pourpanah, Farhad and Hussain, Sadiq and Rezazadegan, Dana and Liu, Li and Ghavamzadeh, Mohammad and Fieguth, Paul and Cao, Xiaochun and Khosravi, Abbas and Acharya, U Rajendra and others},
  journal={Information Fusion},
  volume={76},
  pages={243--297},
  year={2021},
  publisher={Elsevier}
}

@inproceedings{gustafsson2020evaluating,
  title={Evaluating scalable bayesian deep learning methods for robust computer vision},
  author={Gustafsson, Fredrik K and Danelljan, Martin and Schon, Thomas B},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition workshops},
  pages={318--319},
  year={2020}
}

@inproceedings{hafner2020noise,
  title={Noise contrastive priors for functional uncertainty},
  author={Hafner, Danijar and Tran, Dustin and Lillicrap, Timothy and Irpan, Alex and Davidson, James},
  booktitle={Uncertainty in Artificial Intelligence},
  pages={905--914},
  year={2020},
  organization={PMLR}
}

@article{thulasidasan2019mixup,
  title={On mixup training: Improved calibration and predictive uncertainty for deep neural networks},
  author={Thulasidasan, Sunil and Chennupati, Gopinath and Bilmes, Jeff A and Bhattacharya, Tanmoy and Michalak, Sarah},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@article{wen2018flipout,
  title={Flipout: Efficient pseudo-independent weight perturbations on mini-batches},
  author={Wen, Yeming and Vicol, Paul and Ba, Jimmy and Tran, Dustin and Grosse, Roger},
  journal={arXiv preprint arXiv:1803.04386},
  year={2018}
}

@article{szegedy2013intriguing,
  title={Intriguing properties of neural networks},
  author={Szegedy, Christian and Zaremba, Wojciech and Sutskever, Ilya and Bruna, Joan and Erhan, Dumitru and Goodfellow, Ian and Fergus, Rob},
  journal={arXiv preprint arXiv:1312.6199},
  year={2013}
}

@article{bradshaw2017adversarial,
  title={Adversarial examples, uncertainty, and transfer testing robustness in Gaussian process hybrid deep networks},
  author={Bradshaw, John and Matthews, Alexander G de G and Ghahramani, Zoubin},
  journal={arXiv preprint arXiv:1707.02476},
  year={2017}
}

@article{van2017convolutional,
  title={Convolutional gaussian processes},
  author={Van der Wilk, Mark and Rasmussen, Carl Edward and Hensman, James},
  journal={Advances in Neural Information Processing Systems},
  volume={30},
  year={2017}
}

@inproceedings{titsias2009variational,
  title={Variational learning of inducing variables in sparse Gaussian processes},
  author={Titsias, Michalis},
  booktitle={Artificial intelligence and statistics},
  pages={567--574},
  year={2009},
  organization={PMLR}
}


@InProceedings{pmlr-v151-wynne22a,
  title = 	 { Variational Gaussian Processes: A Functional Analysis View },
  author =       {Wynne, George and Wild, Veit},
  booktitle = 	 {Proceedings of The 25th International Conference on Artificial Intelligence and Statistics},
  pages = 	 {4955--4971},
  year = 	 {2022},
  editor = 	 {Camps-Valls, Gustau and Ruiz, Francisco J. R. and Valera, Isabel},
  volume = 	 {151},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {28--30 Mar},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v151/wynne22a/wynne22a.pdf},
  url = 	 {https://proceedings.mlr.press/v151/wynne22a.html},
  abstract = 	 { Variational Gaussian process (GP) approximations have become a standard tool in fast GP inference. This technique requires a user to select variational features to increase efficiency. So far the common choices in the literature are disparate and lacking generality. We propose to view the GP as lying in a Banach space which then facilitates a unified perspective. This is used to understand the relationship between existing features and to draw a connection between kernel ridge regression and variational GP approximations. }
}

@misc{wild2023rigorous,
      title={A Rigorous Link between Deep Ensembles and (Variational) Bayesian Methods},
      author={Veit David Wild and Sahra Ghalebikesabi and Dino Sejdinovic and Jeremias Knoblauch},
      year={2023},
      eprint={2305.15027},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@misc{wild2023connections,
      title={Connections and Equivalences between the Nystr\"om Method and Sparse Variational Gaussian Processes},
      author={Veit Wild and Motonobu Kanagawa and Dino Sejdinovic},
      year={2023},
      eprint={2106.01121},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@book{Kukush_2019, title={Gaussian measures in Hilbert space: Construction and properties}, publisher={ISTE}, author={Kukush, A. G.}, year={2019}}
@inproceedings{wynne2022variational,
  title={Variational gaussian processes: A functional analysis view},
  author={Wynne, George and Wild, Veit},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={4955--4971},
  year={2022},
  organization={PMLR}
}

@misc{lee2018deep,
      title={Deep Neural Networks as Gaussian Processes},
      author={Jaehoon Lee and Yasaman Bahri and Roman Novak and Samuel S. Schoenholz and Jeffrey Pennington and Jascha Sohl-Dickstein},
      year={2018},
      eprint={1711.00165},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@article{terenin2022numerically,
  title={Numerically Stable Sparse Gaussian Processes via Minimum Separation using Cover Trees},
  author={Terenin, Alexander and Burt, David R and Artemev, Artem and Flaxman, Seth and van der Wilk, Mark and Rasmussen, Carl Edward and Ge, Hong},
  journal={arXiv preprint arXiv:2210.07893},
  year={2022}
}

@inproceedings{matthews2016sparse,
  title={On sparse variational methods and the Kullback-Leibler divergence between stochastic processes},
  author={Matthews, Alexander G de G and Hensman, James and Turner, Richard and Ghahramani, Zoubin},
  booktitle={Artificial Intelligence and Statistics},
  pages={231--239},
  year={2016},
  organization={PMLR}
}

@article{burt2020convergence,
  title={Convergence of sparse variational inference in Gaussian processes regression},
  author={Burt, David R and Rasmussen, Carl Edward and Van Der Wilk, Mark},
  journal={The Journal of Machine Learning Research},
  volume={21},
  number={1},
  pages={5120--5182},
  year={2020},
  publisher={JMLRORG}
}
@inproceedings{agdeg1804gaussian,
  title={Gaussian process behaviour in wide deep neural networks},
  author={AGdeG, Matthews and Rowland, M and Hron, J and Turner, RE and Ghahramani, Z},
  booktitle={Proceedings of the 6th international conference on learning representations. arXiv},
  year={1804}
}